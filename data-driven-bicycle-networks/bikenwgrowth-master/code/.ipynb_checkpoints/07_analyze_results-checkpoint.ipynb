{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Analysis of bicycle network results\n",
    "## Project: Data-driven bicycle networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adopted from Michael Szell and modified to fit weighted networks. An addition evaluation metric is added.\n",
    "\n",
    "This notebook takes the existing infrastructure, the results from 03_poi_based_generation and calculates/analyzes a number of measures:\n",
    "* cost (length)\n",
    "* coverage  \n",
    "* directness  \n",
    "* efficiency\n",
    "* overlap with existing networks\n",
    "* population coverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False # If True, will produce plots and/or verbose output to double-check\n",
    "rerun_existing = False # If True, will re-run the costly analysis of existing infra even if files already exist.\n",
    "%run -i \"../parameters/parameters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PATH.\n",
      "\n",
      "Setup finished.\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.2\n",
      "IPython version      : 8.5.0\n",
      "\n",
      "Compiler    : Clang 9.0.1 \n",
      "OS          : Darwin\n",
      "Release     : 18.7.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 40ca8c59f7b566fe66060109a7898e6e783a4eca\n",
      "\n",
      "osmnx     : 0.16.2\n",
      "networkx  : 2.8.6\n",
      "osgeo     : 3.2.1\n",
      "json      : 2.0.9\n",
      "csv       : 1.0\n",
      "pyproj    : 3.4.0\n",
      "geopandas : 0.11.1\n",
      "sys       : 3.8.2 | packaged by conda-forge | (default, Apr 24 2020, 07:56:27) \n",
      "[Clang 9.0.1 ]\n",
      "geojson   : 2.5.0\n",
      "pandas    : 1.4.4\n",
      "shapely   : 1.8.4\n",
      "numpy     : 1.23.3\n",
      "matplotlib: 3.6.0\n",
      "sklearn   : 1.1.2\n",
      "fiona     : 1.8.21\n",
      "igraph    : 0.9.1\n",
      "watermark : 2.3.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i path.py\n",
    "#%run -i setup.py\n",
    "%run -i setupCPH.py\n",
    "if not debug: # Only do this if sure the code is bug-free!\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded functions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -i functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze existing infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    print(placeid + \": Analyzing existing infrastructure.\")    \n",
    "    # output_place is one static file for the existing city. This can be compared to the generated infrastructure.\n",
    "    # Make a check if this file was already generated - it only needs to be done once. If not, generate it:\n",
    "    filename = placeid + \"_existing.csv\"\n",
    "    if rerun_existing or not os.path.isfile(PATH[\"results\"] + placeid + \"/\" + filename):\n",
    "        empty_metrics = {\n",
    "                         \"length\":0,\n",
    "                         \"length_lcc\":0,\n",
    "                         \"coverage\": 0,\n",
    "                         \"directness\": 0,\n",
    "                         \"directness_lcc\": 0,\n",
    "                         \"poi_coverage\": 0,\n",
    "                         \"components\": 0,\n",
    "                         \"pop_den_length\":0,\n",
    "                         \"efficiency_global\": 0, \n",
    "                         \"efficiency_global_routed\": 0,               \n",
    "                         \"directness_lcc_linkwise\": 0,\n",
    "                         \"directness_all_linkwise\": 0\n",
    "                        }\n",
    "        output_place = {}\n",
    "        for networktype in networktypes:\n",
    "            output_place[networktype] = copy.deepcopy(empty_metrics)\n",
    "\n",
    "        # Analyze all networks     \n",
    "        Gs = {}\n",
    "        for networktype in networktypes:\n",
    "            if networktype != \"biketrack_onstreet\" and networktype != \"bikeable_offstreet\":\n",
    "                graph = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, networktype)\n",
    "                Gs[networktype] = graph\n",
    "                graph_simplified = simplify_ig(graph)\n",
    "                Gs[networktype + \"_simplified\"] = graph_simplified\n",
    "                #Gs[networktype] = csv_to_ig_custom(PATH[\"data\"] + placeid + \"/\", placeid, networktype)\n",
    "                #Gs[networktype + \"_simplified\"] = csv_to_ig_custom(PATH[\"data\"] + placeid + \"/\", placeid, networktype + \"_simplified\")\n",
    "            elif networktype == \"biketrack_onstreet\":\n",
    "                graph_biketrack = Gs[\"biketrack\"]\n",
    "                graph_carall =Gs[\"carall\"]\n",
    "                Gs[networktype] = intersect_igraphs(graph_biketrack, graph_carall)\n",
    "                Gs[networktype + \"_simplified\"] = intersect_igraphs(simplify_ig(graph_biketrack), simplify_ig(graph_carall))\n",
    "            elif networktype == \"bikeable_offstreet\":\n",
    "                G_temp = copy.deepcopy(Gs[\"bikeable\"])\n",
    "                delete_overlaps(G_temp, Gs[\"carall\"])\n",
    "                Gs[networktype] = G_temp\n",
    "                G_temp = copy.deepcopy(simplify_ig(Gs[\"bikeable\"]))\n",
    "                delete_overlaps(G_temp, Gs[\"carall_simplified\"])\n",
    "                Gs[networktype + \"_simplified\"] = G_temp\n",
    "\n",
    "        with open(PATH[\"data\"] + placeid + \"/\" + placeid + '_poi_' + poi_source + '_nnidscarall.csv') as f:\n",
    "            nnids = [int(line.rstrip()) for line in f]\n",
    "          \n",
    "        covs = {}\n",
    "        for networktype in tqdm(networktypes, desc = \"Networks\", leave = False):\n",
    "            if debug: print(placeid + \": Analyzing results: \" + networktype)\n",
    "            metrics, cov = calculate_metrics(Gs[networktype], Gs[networktype + \"_simplified\"], Gs['carall'], nnids, empty_metrics, buffer_walk, numnodepairs, debug)\n",
    "           \n",
    "            for key, val in metrics.items():\n",
    "                output_place[networktype][key] = val\n",
    "            covs[networktype] = cov\n",
    "        # Save the covers\n",
    "        write_result(covs, \"pickle\", placeid, \"\", \"\", \"existing_covers.pickle\")\n",
    "        \n",
    "        # Write to CSV\n",
    "        write_result(output_place, \"dictnested\", placeid, \"\", \"\", \"existing.csv\", empty_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze POI based results for all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for placeid, placeinfo in tqdm(cities.items(), desc = \"Cities\"):\n",
    "    print(placeid + \": Analyzing results\")\n",
    "\n",
    "# Load networks   \n",
    "    for attr in attrlist:\n",
    "        G_carall = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, 'carall')\n",
    "        Gexisting = {}\n",
    "        for networktype in [\"biketrack\", \"bikeable\"]:\n",
    "            Gexisting[networktype] = csv_to_ig(PATH[\"data\"] + placeid + \"/\", placeid, networktype)\n",
    "            \n",
    "    # Load POIs\n",
    "        with open(PATH[\"data\"] + placeid + \"/\" + placeid + '_poi_' + poi_source + '_nnidscarall.csv') as f:\n",
    "            nnids = [int(line.rstrip()) for line in f]\n",
    "            \n",
    "    # Load results\n",
    "        filename = placeid + '_poi_' + poi_source + \"_\" + prune_measure + \"_\"+ attr\n",
    "        resultfile = open(PATH[\"results\"] + placeid + \"/\" + filename  +\".pickle\",'rb')\n",
    "        res = pickle.load(resultfile)\n",
    "        resultfile.close()\n",
    "        if debug: pp.pprint(res)\n",
    "       \n",
    "        output, covs = calculate_metrics_additively(res[\"GTs\"], res[\"GT_abstracts\"], res[\"prune_quantiles\"], G_carall, nnids, buffer_walk, numnodepairs, debug, True, Gexisting)\n",
    "        output_MST, cov_MST = calculate_metrics(res[\"MST\"], res[\"MST_abstract\"], G_carall, nnids, output, buffer_walk, numnodepairs, debug, True, ig.Graph(), Polygon(), False, Gexisting)\n",
    "\n",
    "        # Save the covers\n",
    "        write_result(covs, \"pickle\", placeid, poi_source, prune_measure,  \"_\"+ attr+\"_covers.pickle\")\n",
    "    #     write_result(covs_carminusbike, \"pickle\", placeid, poi_source, prune_measure, \"_covers_carminusbike.pickle\")\n",
    "        write_result(cov_MST, \"pickle\", placeid, poi_source, prune_measure, \"_\"+ attr+\"_cover_mst.pickle\")\n",
    "\n",
    "        # Write to CSV\n",
    "        write_result(output, \"dict\", placeid, poi_source, prune_measure, \"_\"+ attr+\".csv\")\n",
    "    #     write_result(output_carminusbike, \"dict\", placeid, poi_source, prune_measure, \"_carminusbike.csv\")\n",
    "    #     write_result(output_carconstrictedbike, \"dict\", placeid, poi_source, prune_measure, \"_carconstrictedbike.csv\")\n",
    "        write_result(output_MST, \"dict\", placeid, poi_source, \"\",  attr+\"_mst.csv\")\n",
    "        covs.clear()\n",
    "        output.clear()\n",
    "        output_MST.clear()\n",
    "        Gexisting.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OSMNX",
   "language": "python",
   "name": "osmnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
